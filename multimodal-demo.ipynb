{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "780832a6",
   "metadata": {},
   "source": [
    "# Generative AI and Multi-Modal Agents in AWS: The Key to Unlocking New Value in Financial Markets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0099f3da",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8413e86e",
   "metadata": {},
   "source": [
    "### Install the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d9f965",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile demo-requirements.txt\n",
    "anthropic==0.2.10\n",
    "boto3==1.26.163\n",
    "langchain==0.0.213\n",
    "PyAthena[SQLAlchemy]==2.25.2\n",
    "sqlalchemy==1.4.47\n",
    "PyPortfolioOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccc2c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r demo-requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3c84a2",
   "metadata": {},
   "source": [
    "please ignore the error message when installing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a39e105",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# modify the region\n",
    "# Make sure it's a region that supports Kendra. https://aws.amazon.com/about-aws/whats-new/2021/06/amazon-kendra-adds-support-for-new-aws-regions/\n",
    "\n",
    "region = 'us-east-2' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f00800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This snippet get the key from secret manager\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "\n",
    "\n",
    "def get_secret():\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        # For a list of exceptions thrown, see\n",
    "        # https://docs.aws.amazon.com/secretsmanager/latest/apireference/API_GetSecretValue.html\n",
    "        raise e\n",
    "\n",
    "    # Decrypts secret using the associated KMS key.\n",
    "    secret = get_secret_value_response['SecretString']\n",
    "\n",
    "    return json.loads(secret)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fb474d",
   "metadata": {},
   "source": [
    "# Use one of the following methods to get Anthropic API Key."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4de2381",
   "metadata": {},
   "source": [
    "Method 1: Retrieve the key from AWS Secrets Manager. Uncomment the code if you use this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035c9958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# secret_name = \"anthropic_key\" #Modify the secret name\n",
    "# ANTHROPIC_API_KEY = get_secret()['anthropic_key']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937a0edd",
   "metadata": {},
   "source": [
    "Method 2: Directly enter the Anthropic API Key. Uncomment the code if you use this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31426ef0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #ANTHROPIC_API_KEY = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cd80d3",
   "metadata": {},
   "source": [
    "### Get resource names\n",
    "\n",
    "The CloudFormation stack created the infrastructure for this application, such as S3 buckets and Lambda functions. We will get the names/ids of these resources. \n",
    "\n",
    "Modify the CFN_STACK_NAME based on the name you used when creating the CloudFormation stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6f4d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify the stack name to match the name of your CloudFormation stack\n",
    "\n",
    "CFN_STACK_NAME = \"multimodal-cf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6867e2ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from typing import List\n",
    "\n",
    "\n",
    "stacks = boto3.client('cloudformation').list_stacks()\n",
    "stack_found = CFN_STACK_NAME in [stack['StackName'] for stack in stacks['StackSummaries']]\n",
    "\n",
    "\n",
    "def get_cfn_outputs(stackname: str) -> List:\n",
    "    cfn = boto3.client('cloudformation')\n",
    "    outputs = {}\n",
    "    for output in cfn.describe_stacks(StackName=stackname)['Stacks'][0]['Outputs']:\n",
    "        outputs[output['OutputKey']] = output['OutputValue']\n",
    "    return outputs\n",
    "\n",
    "\n",
    "\n",
    "# this function extracts the bucket name from S3 uri.\n",
    "# For example, the bucket name is 'my_bucket' based on the URI \"s3://my_bucket/\"\n",
    "def get_bucket_name(s3_uri):\n",
    "    bucket_name = s3_uri.split(\"/\")[2]\n",
    "    return bucket_name\n",
    "\n",
    "\n",
    "if stack_found is True:\n",
    "    outputs = get_cfn_outputs(CFN_STACK_NAME)\n",
    "    glue_db_name = outputs['stockpricesdb']\n",
    "    kendra_index_id = outputs['KendraIndexId']\n",
    "    audio_transcripts_source_bucket = get_bucket_name(outputs['AudioSourceBucket'])\n",
    "    textract_source_bucket = get_bucket_name(outputs['PDFSourceBucket'])\n",
    "    query_staging_bucket = get_bucket_name(outputs['QueryStagingBucket'])\n",
    "    stock_data_source_bucket = get_bucket_name(outputs['StockDataSourceBucket'])\n",
    "    multimodal_output_bucket = get_bucket_name(outputs['MultimodalOutputBucket'])\n",
    "    print (f\"glue_db_name is {glue_db_name}.\")\n",
    "    print (f\"kendra_index_id is {kendra_index_id}.\")\n",
    "    print (f\"audio_transcripts_source_bucket is {audio_transcripts_source_bucket}.\")\n",
    "    print (f\"textract_source_bucket is {textract_source_bucket}.\")\n",
    "    print (f\"query_staging_bucket is {query_staging_bucket}.\")\n",
    "    print (f\"stock_data_source_bucket is {stock_data_source_bucket}.\")\n",
    "    print (f\"multimodal_output_bucket is {multimodal_output_bucket}.\")\n",
    "else:\n",
    "    print(\"Recheck our cloudformation stack name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fa51f4",
   "metadata": {},
   "source": [
    "### Upload the files to the S3 buckets\n",
    "\n",
    "Next, we will upload the documents to the S3 buckets created by CloudFormation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ead09c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import os\n",
    "\n",
    "\n",
    "def upload_file(file_name, bucket, object_name=None):\n",
    "    \"\"\"Upload a file to an S3 bucket\n",
    "\n",
    "    :param file_name: File to upload\n",
    "    :param bucket: Bucket to upload to\n",
    "    :param object_name: S3 object name. If not specified then file_name is used\n",
    "    :return: True if file was uploaded, else False\n",
    "    \"\"\"\n",
    "\n",
    "    # If S3 object_name was not specified, use file_name\n",
    "    if object_name is None:\n",
    "        object_name = os.path.basename(file_name)\n",
    "\n",
    "    # Upload the file\n",
    "    s3_client = boto3.client('s3')\n",
    "    try:\n",
    "        response = s3_client.upload_file(file_name, bucket, object_name)\n",
    "        print (f'Uploaded {file_name} to S3 bucket {bucket}.')\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "\n",
    "upload_file('files/Amazon-10K-2022-EarningsReport.pdf', textract_source_bucket)\n",
    "upload_file('files/Amazon-10Q-Q1-2023-QuaterlyEarningsReport.pdf', textract_source_bucket)\n",
    "upload_file('files/Amazon-Quarterly-Earnings-Report-Q1-2023-Full-Call-v1.mp3', audio_transcripts_source_bucket)\n",
    "upload_file('./files/stock_prices.csv', stock_data_source_bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1fb714",
   "metadata": {},
   "source": [
    "### Create a table in Amazon Athena\n",
    "We will store the stock data in Athena for querying. The stock data has the following format:\n",
    "\n",
    "date|AAAA|FF|BBB|ZZZZ|...\n",
    "\n",
    "AAAA, etc., are fake stock symbols.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30655566",
   "metadata": {},
   "source": [
    "First, drop the existing table as we will create a new one. Copy and past the query in the Athena Query Editor.\n",
    "\n",
    "```\n",
    "DROP TABLE `stock_prices`;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc09fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f\"stock_data_source_bucket is {stock_data_source_bucket}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e09fd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "client = boto3.client('athena')\n",
    "\n",
    "def query_athena(query):\n",
    "    response = client.start_query_execution(\n",
    "        QueryString=query,\n",
    "        QueryExecutionContext={\n",
    "            'Database': 'blog-stock-prices-db'\n",
    "        },\n",
    "        ResultConfiguration={\n",
    "            'OutputLocation': f's3://{query_staging_bucket}/',\n",
    "        },\n",
    "        WorkGroup='primary'\n",
    "    )\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034280c0",
   "metadata": {},
   "source": [
    "Replace the existing table with a new table that imports the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abaaef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_table_query='DROP TABLE `stock_prices`;'\n",
    "query_athena(drop_table_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64893a10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_table_query=f\"\"\"\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS `blog-stock-prices-db`.stock_prices ( \n",
    "    date string, \n",
    "    AAAA double, \n",
    "    FF double, \n",
    "    BBBB double, \n",
    "    ZZZZ double, \n",
    "    GG double, \n",
    "    DDD double, \n",
    "    WWW double, \n",
    "    CCC double, \n",
    "    GGMM double, \n",
    "    TTT double, \n",
    "    UUU double, \n",
    "    SSSS double, \n",
    "    XXX double, \n",
    "    RRR double, \n",
    "    YYY double, \n",
    "    MM double, \n",
    "    PPP double, \n",
    "    JJJ double, \n",
    "    SSXX double\n",
    ") \n",
    "ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'\n",
    "WITH SERDEPROPERTIES ('separatorChar' = ',', 'quoteChar' = '\\\\\\\"', 'escapeChar' = '\\\\\\\\')\n",
    "LOCATION 's3://{stock_data_source_bucket}/'\n",
    "TBLPROPERTIES ('skip.header.line.count'='1')\n",
    "\"\"\"\n",
    "query_athena(create_table_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe16acce",
   "metadata": {},
   "source": [
    "# Create tools\n",
    "\n",
    "In the following section, we will define various tools for the agent. The tools include:\n",
    "    \n",
    "* Stocks Querying Tool to query S&P stocks data using Amazon Athena and SQL Alchemy.\n",
    "* Portfolio Optimization Tool that builds a portfolio based on the chosen stocks.\n",
    "* Financial Information Lookup Tool to search for financial earnings information stored in multi-page pdf files using Amazon Kendra.\n",
    "* Python Calculation Tool that can be used to do mathematical calculations.\n",
    "* Sentiment Analysis Tool to identify and score sentiments on a topic using Amazon Comprehend.\n",
    "* Detect Phrases Tool to find key phrases in recent quarterly reports using Amazon Comprehend.\n",
    "* Text Extraction Tool to convert pdf version of quarterly reports to text files using Amazon Textract.\n",
    "* Transcribe Audio Tool to convert audio recordings to text files using Amazon Transcribe.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d74ccc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain import PromptTemplate,SQLDatabase, SQLDatabaseChain, LLMChain\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "from langchain.chains.api.prompt import API_RESPONSE_PROMPT\n",
    "from langchain.chains import APIChain\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.chat_models import ChatAnthropic\n",
    "from langchain.chains.api import open_meteo_docs\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import expected_returns\n",
    "from langchain.tools import tool\n",
    "from langchain.tools.base import StructuredTool\n",
    "from typing import Optional\n",
    "from langchain.tools import BaseTool\n",
    "from typing import List, Optional\n",
    "\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "from langchain.experimental.plan_and_execute import PlanAndExecute, load_agent_executor, load_chat_planner\n",
    "from langchain.agents.tools import Tool\n",
    "from langchain import LLMMathChain\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.memory.chat_message_histories import DynamoDBChatMessageHistory\n",
    "\n",
    "from typing import Dict\n",
    "import time\n",
    "import uuid\n",
    "import boto3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802b914e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Connect to an LLM\n",
    "\n",
    "llm = ChatAnthropic(temperature=0, anthropic_api_key=ANTHROPIC_API_KEY, max_tokens_to_sample = 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61b7657",
   "metadata": {},
   "source": [
    "## Create Stocks Querying Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58626f0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modify the following parameters as needed\n",
    "table = 'stock_prices'\n",
    "\n",
    "connathena=f\"athena.{region}.amazonaws.com\" \n",
    "portathena='443' #Update, if port is different\n",
    "schemaathena=glue_db_name #from user defined params\n",
    "s3stagingathena=f's3://{query_staging_bucket}/athenaresults/'#from cfn params\n",
    "wkgrpathena='primary'#Update, if workgroup is different\n",
    "\n",
    "##  Create the athena connection string\n",
    "connection_string = f\"awsathena+rest://@{connathena}:{portathena}/{schemaathena}?s3_staging_dir={s3stagingathena}&work_group={wkgrpathena}\"\n",
    "\n",
    "##  Create the athena  SQLAlchemy engine\n",
    "engine_athena = create_engine(connection_string, echo=False)\n",
    "dbathena = SQLDatabase(engine_athena)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440f7b20",
   "metadata": {},
   "source": [
    "<!-- Define the SQL query function. The input of this function will be a prompt in plain English, such as \"What is the size of this table?\" The function will translate the prompt into a SQL query and run the query using the Athena database.\n",
    " -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07159411",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the prompt template for the Stock Querying Tool\n",
    "\n",
    "_DEFAULT_TEMPLATE = \"\"\"\n",
    "    Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer.\n",
    "    \n",
    "    Do not append 'Query:' to SQLQuery.\n",
    "    \n",
    "    For example, if I want to get stock price information for aaaa, gg and ddd, the query should be :\n",
    "    \n",
    "    SELECT date, aaaa, gg, ddd FROM \"blog-stock-prices-db\".\"stock_prices\" order by date asc\n",
    "    \n",
    "    Display SQLResult after the query is run in plain english that users can understand. \n",
    "    \n",
    "\n",
    "    Provide answer in simple english statement.\n",
    " \n",
    "    Only use the following tables:\n",
    "\n",
    "    {table_info}\n",
    "    If someone asks about closing price of a stock, it should be the last price at which a stock trades during a regular trading session.\n",
    "    \n",
    "    Question: {input}\n",
    "    \n",
    "    Provide answer to the input question based on the query results.  \n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9911ba8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_query(query):\n",
    "\n",
    "    PROMPT_sql = PromptTemplate(\n",
    "        input_variables=[\"input\", \"table_info\", \"dialect\"], template=_DEFAULT_TEMPLATE\n",
    "    )\n",
    "    \n",
    "    db_chain = SQLDatabaseChain.from_llm(llm, dbathena, prompt=PROMPT_sql, verbose=True, return_intermediate_steps=False)\n",
    "    response=db_chain.run(query)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5a2b39",
   "metadata": {},
   "source": [
    "Test the run_query tool with a simple question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e7d8ef",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test the run_query tool\n",
    "run_query('What is the size of the table?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3384c1",
   "metadata": {},
   "source": [
    "## Create Portfolio Optimization Tool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8d9e8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import expected_returns\n",
    "from langchain.tools import tool\n",
    "from langchain.tools.base import StructuredTool\n",
    "from typing import Optional\n",
    "from langchain.tools import BaseTool\n",
    "from typing import List, Optional\n",
    "\n",
    "\n",
    "class OptimizePortfolio(BaseTool):\n",
    "    \n",
    "    import pandas as pd\n",
    "    \n",
    "    name = \"Portfolio Optimization Tool\"\n",
    "    description = \"\"\"\n",
    "        use this tool when you need to build optimal portfolio. \n",
    "        The output results tell you the allocation of your money on each stock.\n",
    "        The stock_ls should be a list of stock symbols, such as ['WWW', 'DDD', 'AAAA'].\n",
    "        \"\"\"\n",
    "\n",
    "    \n",
    "    def _run(self, stock_ls: List):\n",
    "        \n",
    "        import boto3\n",
    "        import pandas as pd\n",
    "        from pyathena import connect\n",
    "        \n",
    "        # Establish connection to Athena\n",
    "        session = boto3.Session(region_name=region)\n",
    "        athena_client = session.client('athena')\n",
    "\n",
    "        # Execute query\n",
    "\n",
    "        stock_seq = ', '.join(stock_ls)\n",
    "        query = f'SELECT date, {stock_seq} from \"{glue_db_name}\".\"{table}\"'\n",
    "        print (f'query:{query}')\n",
    "        cursor = connect(s3_staging_dir=f's3://{query_staging_bucket}/athenaresults/', region_name=region).cursor()\n",
    "        cursor.execute(query)\n",
    "\n",
    "        # Fetch results\n",
    "        rows = cursor.fetchall()\n",
    "\n",
    "        # Convert to Pandas DataFrame\n",
    "        df = pd.DataFrame(rows, columns=[column[0] for column in cursor.description])\n",
    "\n",
    "        # Set \"Date\" as the index and parse it as a datetime object\n",
    "        df.set_index(\"date\", inplace=True)\n",
    "        df.index = pd.to_datetime(df.index, format = '%Y-%m-%d')\n",
    "        \n",
    "        mu = expected_returns.mean_historical_return(df)\n",
    "        S = risk_models.sample_cov(df)\n",
    "\n",
    "        # Optimize for maximal Sharpe ratio\n",
    "        ef = EfficientFrontier(mu, S)\n",
    "        weights = ef.max_sharpe()\n",
    "        ef.portfolio_performance(verbose=True)\n",
    "\n",
    "        cleaned_weights = ef.clean_weights()\n",
    "        print (f'cleaned_weights are {dict(cleaned_weights)}')\n",
    "\n",
    "        ef.portfolio_performance(verbose=True)\n",
    "\n",
    "        #Finally, let’s convert the weights into actual allocations values (i.e., how many of each stock to buy). For our allocation, let’s consider an investment amount of $100,000:\n",
    "\n",
    "        from pypfopt.discrete_allocation import DiscreteAllocation, get_latest_prices\n",
    "\n",
    "\n",
    "        latest_prices = get_latest_prices(df)\n",
    "\n",
    "        da = DiscreteAllocation(weights, latest_prices, total_portfolio_value=10000)\n",
    "        allocation, leftover = da.greedy_portfolio()\n",
    "        print(\"Discrete allocation:\", allocation)\n",
    "        print(\"Funds remaining: ${:.2f}\".format(leftover))\n",
    "        print (allocation)\n",
    "        return cleaned_weights\n",
    "\n",
    "    def _arun(self, stock_ls: int):\n",
    "        raise NotImplementedError(\"This tool does not support async\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bd5485",
   "metadata": {},
   "source": [
    "# Define tools that use Amazon Comprehend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576aa82e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def SentimentAnalysis(inputString):\n",
    "    print(inputString)\n",
    "    lambda_client = boto3.client('lambda')\n",
    "    lambda_payload = {\"inputString:\"+inputString}\n",
    "    response=lambda_client.invoke(FunctionName='FSI-SentimentDetecttion',\n",
    "                        InvocationType='RequestResponse',\n",
    "                     Payload=json.dumps(inputString))\n",
    "    output=json.loads(response['Payload'],read().decode())\n",
    "    return output['body']\n",
    "\n",
    "def DetectKeyPhrases(inputString):\n",
    "    print(inputString)\n",
    "    lambda_client = boto3.client('lambda')\n",
    "    lambda_payload = {\"inputString:\"+inputString}\n",
    "    response=lambda_client.invoke(FunctionName='FSI-KeyPhrasesDetection',\n",
    "                        InvocationType='RequestResponse',\n",
    "                     Payload=json.dumps(inputString))\n",
    "    output=json.loads(response['Payload'],read().decode())\n",
    "    return output['body']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2139143c",
   "metadata": {},
   "source": [
    "# Define tool that uses AWS Textract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521bb95f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def IntiateTextExtractProcessing(inputString):\n",
    "    print(inputString)\n",
    "    lambda_client = boto3.client('lambda')\n",
    "    lambda_payload = {\"inputString:\"+inputString}\n",
    "    response=lambda_client.invoke(FunctionName='FSI-TextractAsyncInvocationFunction',\n",
    "                        InvocationType='RequestResponse',\n",
    "                     Payload=json.dumps(inputString))\n",
    "    print(response['Payload'].read())\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0b0bda",
   "metadata": {},
   "source": [
    "# Define tool that uses Amazon Transcribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bab006b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def TranscribeAudio(inputString):\n",
    "    print(inputString)\n",
    "    lambda_client = boto3.client('lambda')\n",
    "    lambda_payload = {\"inputString:\"+inputString}\n",
    "    response=lambda_client.invoke(FunctionName='FSI-Transcribe',\n",
    "                        InvocationType='RequestResponse',\n",
    "                     Payload=json.dumps(inputString))\n",
    "    print(response['Payload'].read())\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa78898",
   "metadata": {},
   "source": [
    "# Create Financial Information Lookup Tool \n",
    "\n",
    "Kendra helps you find faster with intelligent enterprise search powered by machine learning. We will use Kendra to find answers in *Amazon-10K-2022-EarningsReport.pdf*, *Amazon-10Q-Q1-2023-QuaterlyEarningsReport.pdf* and trasncriptions of *Amazon-Quarterly-Earnings-Report-Q1-2023-Full-Call-v1.mp3*.\n",
    "\n",
    "Sample question: “What’s Amazon’s unearned revenue from AWS and Prime memberships as of December 31, 2022? What is the profitability ratio as of December 31, 2022\"\n",
    "\n",
    "First, we to do two pre-processing steps to extract the text of the PDF files. This process takes about 15 minutes to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e8656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "IntiateTextExtractProcessing('process')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9bf385",
   "metadata": {},
   "source": [
    "Next, we need to transcribe the .mpd audio file. This also takes about 15 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b084cc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "TranscribeAudio('process')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2706556c",
   "metadata": {},
   "source": [
    "The above process takes about 15 minutes. The code below will check the S3 bucket every minute. If the process is completed, the code will show \"The S3 bucket contains all the necessary output.\", and please proceed to the next cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de359b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_s3_files_using_client(bucket):\n",
    "    \"\"\"\n",
    "    This functions list all files in s3 bucket.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    s3_client=boto3.client(\"s3\")\n",
    "    bucket_name=bucket\n",
    "    response=s3_client.list_objects_v2(Bucket=bucket_name)\n",
    "    files=response.get(\"Contents\")\n",
    "    output_list=[]\n",
    "    for file in files:\n",
    "        output_list.append(file['Key'])\n",
    "    return output_list\n",
    "\n",
    "correct_list = [\n",
    "    'audiooutputs/Amazon-Quarterly-Earnings-Report-Q1-2023-Full-Call-v1.txt',\n",
    "    'pdfoutputs/Amazon-10K-2022-EarningsReport.txt',\n",
    "    'pdfoutputs/Amazon-10Q-Q1-2023-QuaterlyEarningsReport.txt'\n",
    "]\n",
    "\n",
    "\n",
    "s3_files_list=list_s3_files_using_client(multimodal_output_bucket)\n",
    "check =  all(item in s3_files_list for item in correct_list)\n",
    " \n",
    "while not check:\n",
    "    time.sleep(30)\n",
    "    s3_files_list=list_s3_files_using_client(multimodal_output_bucket)\n",
    "    check =  all(item in s3_files_list for item in correct_list)\n",
    "else:\n",
    "    print ('The S3 bucket contains all the necessary output. Please proceed.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bffdc41",
   "metadata": {},
   "source": [
    "Next, we are going to sync Amazon Kendra with the text files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2d8f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from typing import List\n",
    "\n",
    "\n",
    "stacks = boto3.client('cloudformation').list_stacks()\n",
    "stack_found = CFN_STACK_NAME in [stack['StackName'] for stack in stacks['StackSummaries']]\n",
    "\n",
    "\n",
    "def get_cfn_outputs(stackname: str) -> List:\n",
    "    cfn = boto3.client('cloudformation')\n",
    "    outputs = {}\n",
    "    for output in cfn.describe_stacks(StackName=stackname)['Stacks'][0]['Outputs']:\n",
    "        outputs[output['OutputKey']] = output['OutputValue']\n",
    "    return outputs\n",
    "\n",
    "\n",
    "\n",
    "# this function extracts the bucket name from S3 uri.\n",
    "# For example, the bucket name is 'my_bucket' based on the URI \"s3://my_bucket/\"\n",
    "def get_bucket_name(s3_uri):\n",
    "    bucket_name = s3_uri.split(\"/\")[2]\n",
    "    return bucket_name\n",
    "\n",
    "\n",
    "if stack_found is True:\n",
    "    outputs = get_cfn_outputs(CFN_STACK_NAME)\n",
    "    glue_db_name = outputs['stockpricesdb']\n",
    "    kendra_index_id = outputs['KendraIndexId']\n",
    "    kendra_data_source_id = outputs['KendraDataSourceId']\n",
    "    audio_transcripts_source_bucket = get_bucket_name(outputs['AudioSourceBucket'])\n",
    "    textract_source_bucket = get_bucket_name(outputs['PDFSourceBucket'])\n",
    "    query_staging_bucket = get_bucket_name(outputs['QueryStagingBucket'])\n",
    "    stock_data_source_bucket = get_bucket_name(outputs['StockDataSourceBucket'])\n",
    "    multimodal_output_bucket = get_bucket_name(outputs['MultimodalOutputBucket'])\n",
    "    \n",
    "    print (f\"glue_db_name is {glue_db_name}.\")\n",
    "    print (f\"kendra_index_id is {kendra_index_id}.\")\n",
    "    print (f\"kendra_data_source_id is {kendra_data_source_id}.\")\n",
    "    print (f\"audio_transcripts_source_bucket is {audio_transcripts_source_bucket}.\")\n",
    "    print (f\"textract_source_bucket is {textract_source_bucket}.\")\n",
    "    print (f\"query_staging_bucket is {query_staging_bucket}.\")\n",
    "    print (f\"stock_data_source_bucket is {stock_data_source_bucket}.\")\n",
    "    print (f\"multimodal_output_bucket is {multimodal_output_bucket}.\")\n",
    "else:\n",
    "    print(\"Recheck our cloudformation stack name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90287dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "kendra_client = boto3.client(\"kendra\")\n",
    "\n",
    "sync_response = kendra_client.start_data_source_sync_job(\n",
    "    Id = kendra_data_source_id,\n",
    "    IndexId = kendra_index_id\n",
    ")\n",
    "\n",
    "print(\"Wait for the data source to sync with the index.\")\n",
    "\n",
    "time.sleep(30)\n",
    "\n",
    "while True:\n",
    "    jobs = kendra_client.list_data_source_sync_jobs(\n",
    "        Id = kendra_data_source_id,\n",
    "        IndexId = kendra_index_id\n",
    "    )\n",
    "\n",
    "    status = jobs[\"History\"][0][\"Status\"]\n",
    "    print(\" Syncing data source. Status: \"+status)\n",
    "    \n",
    "    if status != \"SYNCING\":\n",
    "        break\n",
    "    time.sleep(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9141a834-7ad8-4ddf-8907-20f0c5c3d23b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers import AmazonKendraRetriever\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "import os\n",
    "from langchain.chat_models import ChatAnthropic\n",
    "\n",
    "\n",
    "def build_chain():\n",
    "       \n",
    "    retriever = AmazonKendraRetriever(index_id=kendra_index_id)\n",
    "\n",
    "    prompt_template = \"\"\"\n",
    "\n",
    "      Human: This is a friendly conversation between a human and an AI. \n",
    "      The AI is talkative and provides specific details from its context but limits it to 240 tokens.\n",
    "      If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "      Net income can be net loss. If the value is in paranthesis, it means it is a loss and hence a negative value. For example, (1000) means -1000.\n",
    "    \n",
    "      \n",
    "      Assistant: OK, got it, I'll be a talkative truthful AI assistant.\n",
    "\n",
    "      Human: Here are a few documents: {context}\n",
    "      Based on the above documents, provide a straightforward answer for {question}. \n",
    "      Answer \"don't know\" if not present in the document. \n",
    "\n",
    "      Assistant:\"\"\"\n",
    "    \n",
    "    PROMPT = PromptTemplate(\n",
    "        template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "\n",
    "    chain_type_kwargs = {\"prompt\": PROMPT}\n",
    " \n",
    "    return RetrievalQA.from_chain_type(\n",
    "        llm, \n",
    "        chain_type=\"stuff\", \n",
    "        retriever=retriever, \n",
    "        chain_type_kwargs=chain_type_kwargs,\n",
    "        return_source_documents=True\n",
    "    )\n",
    "\n",
    "\n",
    "def run_chain(prompt: str, history=[]):\n",
    "    chain = build_chain()\n",
    "    result = chain(prompt)\n",
    "    return {\n",
    "        \"answer\": result['result'],\n",
    "        \"source_documents\": result['source_documents']\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbb6f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the tool\n",
    "result = run_chain(\"What's Amazon's total unearned revenue in 2022?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051a0cb9",
   "metadata": {},
   "source": [
    "# Define a toolkit\n",
    "\n",
    "Now that we have defined all the individual tools, we will put together a toolkit for the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f5c76f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents.tools import Tool\n",
    "from langchain.experimental.plan_and_execute import PlanAndExecute, load_agent_executor, load_chat_planner\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Stock Querying Tool\",\n",
    "        func=run_query,\n",
    "        description=\"\"\"\n",
    "        Useful for when you need to answer questions about stocks. It only has information about stocks.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    OptimizePortfolio(),\n",
    "    Tool(\n",
    "        name=\"Financial Information Lookup Tool\",\n",
    "        func=run_chain,\n",
    "        description=\"\"\"\n",
    "        Useful for when you need to look up financial information using kendra. \n",
    "        \"\"\"\n",
    "    ),\n",
    "    PythonREPLTool(),\n",
    "    Tool(\n",
    "        name=\"Sentiment Analysis Tool\",\n",
    "        func=SentimentAnalysis,\n",
    "        description=\"\"\"\n",
    "        Useful for when you need to analyze the sentiment of a topic, such as \"Return to Office\".\n",
    "        \"\"\"\n",
    "    ),\n",
    "     Tool(\n",
    "        name=\"Detect Phrases Tool\",\n",
    "        func=DetectKeyPhrases,\n",
    "        description=\"\"\"\n",
    "        Useful for when you need to detect key phrases in recent quaterly reports.\n",
    "        \"\"\"\n",
    "    ),\n",
    "     Tool(\n",
    "        name=\"Text Extraction Tool\",\n",
    "        func=IntiateTextExtractProcessing,\n",
    "        description=\"\"\"\n",
    "        Useful for when you need to trigger conversion of  pdf version of quaterly reports to text files using amazon textextract\n",
    "        \"\"\"\n",
    "    ),\n",
    "     Tool(\n",
    "        name=\"Transcribe Audio Tool\",\n",
    "        func=TranscribeAudio,\n",
    "        description=\"\"\"\n",
    "        Useful for when you need to convert audio recordings of earnings calls from audio to text format using Amazon Transcribe\n",
    "        \"\"\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14e4d42",
   "metadata": {},
   "source": [
    "Modify the prompt template to provide the agent guidance on how to use the tools. The current template of prompt is based on Anthropic Claude2. If you choose to use a different foundation model, please try tweaking the template. It's just like you would convey the same idea in slightly different ways to different people. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed88c70b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combo_template = \"\"\"\n",
    "    \n",
    "    Let's first understand the problem and devise a plan to solve the problem. \n",
    "    Please output the plan starting with the header 'Plan:' and then followed by a numbered list of steps. Do not use past conversation history when you are planning the steps.\n",
    "    Please make the plan the minimum number of steps required to accurately complete the task. \n",
    "        \n",
    "    \n",
    "    These are guidance on when to use a tool to solve a task, follow them strictly:  \n",
    "    \n",
    "    - When you need to find stock information, use \"Stock Querying Tool\" tool, as it provides more accurate and relevant answers. Pay attention to the time period. DO NOT search for answers on the internet.\n",
    "    \n",
    "    - When you need to look up financial information, such as revenue and income, use the \"Financial Information Lookup Tool\". \n",
    "    \n",
    "    - When you need to find the key phrases information from quaterly report then use Detect Phrases Tool to get the information about all key phrases and respond with key phrases relavent to the question.\n",
    "\n",
    "    - When you need to provide an optimized stock portfolio based on stock names, use Portfolio Optimization Tool. The output is the percent of fund you should spend on each stock.\n",
    "    \n",
    "    - When you need to do maths calculations, use \"PythonREPLTool()\" which is based on the python programming language. Only provide the required numerical values to this tool and test, for e.g. \"stock_prices\": [25, 50, 75] only pass in [25, 50, 75] not the text \"stock prices:\"\n",
    "    \n",
    "    - When you need to analyze sentiment of a topic, use \"Sentiment Analysis Tool\".\n",
    "    \n",
    "    \n",
    "    \"Closing price\" means the most recent stock price of the time period. \n",
    "    \n",
    "    Alternatively, When you come across values required from income statement, look for values from Annual Income Statement stored in csv format. \n",
    "           \n",
    "    Income can be a positive (profit) or negative value (loss). If the value is in parenthesis (), take it as negative value, which means it's a loss. E.g. for (1000), use -1000.\n",
    "         \n",
    "    When you have a question about calculating a ratio, figure out the formula for the calculation, and find the relevant financial information using the proper tool. Then use PythonREPLTool() tool for calculation.\n",
    "\n",
    "    If you can't find the answer, say \"I can't find the answer for this question.\"\n",
    "    \n",
    "    DO NOT CREATE STEPS THAT ARE NOT NEEDED TO SOLVE A TASK. \n",
    "    \n",
    "    Once you have answers for the question, stop and provide the final answers. The final answers should be a combination of the answers to all the questions, not just the last one.\n",
    "    \n",
    "    Please make sure you have a plan to answer all the questions in the input, not just the last one. \n",
    "    Sometimes the two questions are related, sometimes they are not. So in the end, include the answers for both questions.\n",
    "    Please use these to construct an answer to the question , as though you were answering the question directly. Ensure that your answer is accurate and doesn’t contain any information not directly supported by the summary and quotes.\n",
    "    If there are no data or information in this document that seem relevant to this question, please just say \"I can’t find any relevant quotes\".\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf0033e-7b63-495d-b865-4e22de5ae72c",
   "metadata": {},
   "source": [
    "Adding a conversation history element to the bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1dc0b6-134e-4e4e-a973-ce16147e6b6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat_history_table = 'SessionTable' # Name of dynamoDB Table for storing converstaions (prompts and answers)\n",
    "  \n",
    "chat_session_id = '0'\n",
    "  \n",
    "if chat_session_id == '0' :\n",
    "    chat_session_id = str(uuid.uuid4())\n",
    "\n",
    "print (chat_session_id)\n",
    "\n",
    "chat_history_memory = DynamoDBChatMessageHistory(table_name=chat_history_table, session_id=chat_session_id)\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", chat_memory=chat_history_memory, return_messages=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0914f093",
   "metadata": {},
   "source": [
    "The agent has two parts, a planner and an executor. The planner sets up the steps necessary to answer the questions, and the executor carries out the plans using the tools in the toolkit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc47e030",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "planner = load_chat_planner(llm)\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(combo_template)\n",
    "human_message_prompt = planner.llm_chain.prompt.messages[1]\n",
    "planner.llm_chain.prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "executor = load_agent_executor(llm, tools, verbose=True)\n",
    "agent = PlanAndExecute(planner=planner, executor=executor, verbose=True, max_iterations=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2380dd65",
   "metadata": {},
   "source": [
    "# Ask the agent questions!\n",
    "\n",
    "Please note that the results are non-deterministic becuase of the nature of Large Languaeg Models (LLM), so what you get each time can be different, and they can also be different from what are in the blog posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c84158",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output = agent(\"What are the closing prices of stocks AAAA, WWW, DDD in year 2018? Can you build an optimized portfolio using these three stocks? Please provide answers to both questions.\")\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
